#include <iostream>
#include <string>
#include <fstream>
// #include <cmath>
// #include <cassert>
// #include <chrono>
// #include <cuda_runtime.h>

// We'll assume you define bf16 somewhere, e.g. in "kittens.cuh"
// #include "kittens.cuh" 

// If your forward kernel and global definitions live in "delta_attn.cu" or "delta_attn.cuh", 
// you might need something like:
// #include "delta_attn.cuh"

// Adjust these as needed:
constexpr int ATTN_B     = 8; //1; // 16;  // B
constexpr int QO_HEADS   = 16; //1; // 8;  // Query/Output heads
// constexpr int KV_HEADS   = 8 // 1;  // Key/Value heads
constexpr int ATTN_N     = 128; // Sequence length
// constexpr int ATTN_D     = 16;  // Head dimension
constexpr bool causal    = true;

//static_assert(QO_HEADS == KV_HEADS, "For minimal code, set QO_HEADS == KV_HEADS.");


#define NUM_WORKERS 8
#define BLOCK_SIZE  (32*NUM_WORKERS)
constexpr int ITER = 10;

// Simple CUDA error checking
#define CudaCheckError() __cudaCheckError(__FILE__, __LINE__)
inline void __cudaCheckError(const char* file, int line) {
    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
        std::cerr << "CUDA error at " << file << ":" << line << " -> "
                  << cudaGetErrorString(err) << std::endl;
        exit(-1);
    }
    err = cudaDeviceSynchronize();
    if (err != cudaSuccess) {
        std::cerr << "CUDA sync error at " << file << ":" << line << " -> "
                  << cudaGetErrorString(err) << std::endl;
        exit(-1);
    }
}

// Example function to compute a “fake” flop count
// long long flops_fwd(int B, int N, int D, int nheads) {
//     // Arbitrary estimate: Q @ K^T + (Q@K^T) @ V => ~2*N*N*D for each head
//     // Times B & nheads:
//     long long f = 2LL * B * nheads * N * N * D;
//     // E.g. if you want to consider "causal" => maybe f/=2;
//     return f;
// }
// long long flops_ref(int B, int N, int H) {
//     // Q@K.T and (Q@K.T)@V for a parallel view
//     long long flops = 2LL * B * H * N * N * ATTN_D 
//                       + 2LL * B * H * N * N * ATTN_D;
//     return flops;
// }

// long long flops_real(int B, int N, int H) {
//     // Flops for a chunk-wise strategy.
//     int chunk_size = ACTIVE_TILES * ROWS;
//     int n_chunks = N / chunk_size;
//     long long flops = n_chunks * (2LL * B * H * chunk_size * chunk_size * ATTN_D 
//                                   + 2LL * B * H * chunk_size * chunk_size * ATTN_D);
//     return flops;
// }


// // Convert microseconds to TFLOPS
// double efficiency(long long flop, double time_us) {
//     // flop -> TFlop ; time_us -> ms
//     double tflop = flop / 1e12;      // from flop to TFlop
//     double ms    = time_us / 1e3;    // from microseconds to milliseconds
//     return tflop / (ms / 1e3);       // TFlop / seconds
//     // Equivalently: ( tflop / (ms*1e-3) )
// }

// Compute FLOPs for forward attention
// constexpr uint64_t ATTN_FLOPS = 
//     2llu * ATTN_B * ATTN_H * ATTN_N * ATTN_N * ATTN_D + // Q * K^T: 2BHNND (multiply-add)
//     4llu * ATTN_B * ATTN_H * ATTN_N * ATTN_N +          // Softmax: 2BHNN (exp and divide, plus flash-attn bookkeeping)
//     2llu * ATTN_B * ATTN_H * ATTN_N * ATTN_N * ATTN_D;      // (Q * K^T) * V: 2BHNND (multiply-add)

int main(int argc, char** argv) {
    if (argc < 2) {
        std::cerr << "Usage: ./fwd_harness_minimal <test_file.txt>" << std::endl;
        return -1;
    }
    const char* filename = argv[1];

    // Derived sizes
    constexpr int TOTAL_ELEMENTS = ATTN_B*QO_HEADS*ATTN_N*ATTN_D;
    constexpr int TOTAL_UNIQUE_ELEMENTS = QO_HEADS*ATTN_N*ATTN_D;

    // Allocate host buffers for single-head (the “unique” data)
    float *q = new float[TOTAL_ELEMENTS];
    float *k = new float[TOTAL_ELEMENTS];
    float *v = new float[TOTAL_ELEMENTS];
    float *o_ref = new float[TOTAL_ELEMENTS];

    // Large buffers for the final (replicated) device input
    bf16 *q_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *k_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *v_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *o_bf = new bf16[TOTAL_ELEMENTS];
    float *o = new float[TOTAL_ELEMENTS];

    // Read from file
    std::ifstream infile(filename);
    if (!infile.is_open()) {
        std::cerr << "Could not open " << filename << std::endl;
        return -1;
    }
    // For minimal code, read Q, then K, then V, then O_ref: //DID removed the TOTAL_ELEMENTS/ATTN_B
    for(int i = 0; i < TOTAL_ELEMENTS; i++) infile >> q[i];
    std::cout << "Finished loading Q" << std::endl;
    for(int i = 0; i < TOTAL_ELEMENTS; i++) infile >> k[i];
    std::cout << "Finished loading K" << std::endl;
    for(int i = 0; i < TOTAL_ELEMENTS; i++) infile >> v[i];
    std::cout << "Finished loading V" << std::endl;
    for(int i = 0; i < TOTAL_ELEMENTS; i++) infile >> o_ref[i];
    std::cout << "Finished loading O_REF" << std::endl;

    std::cout << "Finished loading file from " << argv[1] << "!" << std::endl;
    // infile.close();

    // Replicate across batch & heads
    for(int i = 0; i < TOTAL_ELEMENTS; i++) {
        // q_bf[i] = __float2bfloat16(q[i % (TOTAL_ELEMENTS/ATTN_B)]);
        // k_bf[i] = __float2bfloat16(k[i % (TOTAL_ELEMENTS/ATTN_B)]);
        // v_bf[i] = __float2bfloat16(v[i % (TOTAL_ELEMENTS/ATTN_B)]);
        q_bf[i] = __float2bfloat16(q[i]);
        k_bf[i] = __float2bfloat16(k[i]);
        v_bf[i] = __float2bfloat16(v[i]);
    }

    // Device memory
    bf16 *d_q, *d_k, *d_v, *d_o;
    cudaMalloc(&d_q, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_k, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_v, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_o, TOTAL_ELEMENTS * sizeof(bf16));

    // Copy
    cudaMemcpy(d_q, q_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_k, k_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_v, v_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);
    //cudaMemset(d_o, 0, TOTAL_ELEMENTS_QO * sizeof(bf16));

    // Build minimal forward “globals” structure.
    // We assume you have something like:
    // fwd_globals fwd_init(bf16*,bf16*,bf16*,bf16*,unsigned long B, unsigned long H, unsigned long N);
    // And a kernel named: template<int HEAD_DIM, bool CAUSAL> __global__ void fwd_attend_ker(...).
    // Adjust as necessary.

    fwd_globals g = fwd_init(
        d_q, d_k, d_v, d_o,
        ATTN_B, QO_HEADS, ATTN_N
    );

    // global_layout<ATTN_D> Qg(d_q, ATTN_B, ATTN_N, ATTN_H, nullptr);
    // global_layout<ATTN_D> Kg(d_k, ATTN_B, ATTN_N, ATTN_H, nullptr);
    // global_layout<ATTN_D> Vg(d_v, ATTN_B, ATTN_N, ATTN_H, nullptr);
    // global_layout<ATTN_D> Og(d_o, ATTN_B, ATTN_N, ATTN_H, nullptr);

    // globals<ATTN_D> g(Qg, Kg, Vg, Og);

    cudaDeviceSynchronize();
    CudaCheckError();
    
    // Launch
    unsigned long mem_size = kittens::MAX_SHARED_MEMORY; // or kittens::MAX_SHARED_MEMORY
    std::cout << "Setting max block shared memory to " << mem_size << std::endl;

    cudaFuncSetAttribute(
        delta_attention_fwd,
        cudaFuncAttributeMaxDynamicSharedMemorySize,
        mem_size
    );
    CudaCheckError();
    cudaDeviceSynchronize();


    dim3 grid(QO_HEADS, ATTN_B); //TODO verify proper grid initialization
    dim3 block(BLOCK_SIZE);

    // Warmup
    std::cout << "Warmup!\n";
    for(int i=0; i<ITER; i++){
        delta_attention_fwd<<<grid, NUM_THREADS, mem_size>>>(g);
    }
    cudaDeviceSynchronize();
    CudaCheckError();

    std::cout << "Starting main forward kernel...\n";
    auto start = std::chrono::high_resolution_clock::now();
    for(int i=0; i<ITER; i++){
        delta_attention_fwd<<<grid, NUM_THREADS, mem_size>>>(g);
    }

    cudaDeviceSynchronize();
    auto finish = std::chrono::high_resolution_clock::now();
    CudaCheckError();

    double time_us = std::chrono::duration_cast<std::chrono::microseconds>(finish - start).count() / (double)ITER;
    std::cout << "Done. Average time: " << time_us << " us\n";


    /*************************** Correctness Checks **************************** */
    
    // cudaMemcpy(h_o_bf, d_o, TOTAL_ELEMENTS_QO * sizeof(bf16), cudaMemcpyDeviceToHost);
    // for(int i=0; i < TOTAL_ELEMENTS_QO; i++){
    //     h_o[i] = __bfloat162float(h_o_bf[i]);
    // }

    // // Compare unique portion
    // double total_diff = 0.0;
    // double max_diff   = 0.0;
    // for(int i=0; i<UNIQUE_ELEMENTS_QO; i++){
    //     double diff = h_o[i] - h_o_ref[i];
    //     total_diff += std::fabs(diff);
    //     if(std::fabs(diff) > max_diff) max_diff = std::fabs(diff);
    // }
    // std::cout << "Average diff: " << (total_diff / UNIQUE_ELEMENTS_QO) << "\n"
    //           << "Max diff: " << max_diff << "\n";

    // // Efficiency
    // long long flop = flops_fwd(ATTN_B, ATTN_N, ATTN_D, QO_HEADS);
    // double tflops  = efficiency(flop, time_us);
    // std::cout << "Approx. Efficiency: " << tflops << " TFLOPS\n";

    // Copy device output to host BF16 buffer and convert to float.
    cudaMemcpy(o_bf, d_o, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyDeviceToHost);
    for (int i = 0; i < TOTAL_ELEMENTS; i++) {
        o[i] = __bfloat162float(o_bf[i]);
    }

    // Detailed diagnostic: write outputs to files and compute error metrics.
    bool good = true;
    std::ofstream o_ref_file("printouts/o_ref.txt");
    std::ofstream o_file("printouts/o.txt");
    std::ofstream diff_file("printouts/diff.txt");

    double total_diff = 0.0;
    double max_diff = 0.0;

    std::cout << "Total elements (full tensor): " << TOTAL_ELEMENTS << std::endl;
    std::cout << "Unique elements (per-head): " << TOTAL_ELEMENTS << std::endl;

    // Print first 10 outputs for sanity checking.
    for (int i = 0; i < 10; i++) {
        std::cout << "o[" << i << "] = " << o[i] 
                << "    o_ref[" << i << "] = " << o_ref[i] << std::endl;
    }

    // Compare only the unique portion (e.g. one head’s data).
    for (int i = 0; i < TOTAL_ELEMENTS; i++) {
        float diff = o[i] - o_ref[i];
        // Write the reference, computed, and difference values to files.
        o_ref_file << o_ref[i] << ' ';
        o_file << o[i] << ' ';
        if (i % 128 == 0) {
            diff_file << "\n";
        }
        diff_file << diff << ' ';
        

        if (fabs(diff) > 0.05 || isnan(diff)) {
            good = false;
        }
        total_diff += fabs(diff);
        if (fabs(diff) > max_diff) {
            max_diff = fabs(diff);
        }
    }
    o_ref_file.close();
    o_file.close();
    diff_file.close();

    double avg_diff = total_diff / TOTAL_ELEMENTS; // TODO fix
    std::cout << "Max difference: " << max_diff << std::endl;
    std::cout << "Average difference: " << avg_diff << std::endl;
    if (good)
        std::cout << "Output is correct :)" << std::endl;
    else
        std::cout << "Output is incorrect :(" << std::endl;

    // Efficiency calculations.
    double avg_exec_time = std::chrono::duration_cast<std::chrono::microseconds>(finish - start).count() / (double)ITER;
    std::cout << "Average kernel execution time: " << avg_exec_time << " us" << std::endl;

    // long long flop_ref = flops_fwd(ATTN_B, ATTN_N, ATTN_D, QO_HEADS);
    // long long flop_real = flops_real(ATTN_B, ATTN_N, ATTN_D, QO_HEADS);
    // long long f_ref = flops_ref(ATTN_B, ATTN_N, ATTN_H);
    // long long f_real = flops_real(ATTN_B, ATTN_N, ATTN_H); 

    // double e_ref = efficiency(flop_ref, avg_exec_time);
    // double e_real = efficiency(flop_real, avg_exec_time);
    // std::cout << "Efficiency (ref): " << e_ref << " TFLOPS" << std::endl;
    // std::cout << "Efficiency (real): " << e_real << " TFLOPS" << std::endl;

    // Cleanup
    cudaFree(d_q);
    cudaFree(d_k);
    cudaFree(d_v);
    cudaFree(d_o);

    delete[] q;
    delete[] k;
    delete[] v;
    delete[] o_ref;
    delete[] q_bf;
    delete[] k_bf;
    delete[] v_bf;
    delete[] o_bf;
    delete[] o;

    return 0;
}
